# Chapter 1: Basics of Deep Learning

Welcome to the code repo for Chapter 1 of the book. The code requires Jupyter notebook installed, along with TensorFlow. Standard libraries like `numpy`, `scipy`, `matplotlib` etc are also required. If you have followed the instructions from the appendix, then you should be all set!

## Data set
For this chapter, we will use the [EMNIST](https://www.nist.gov/itl/iad/image-group/emnist-dataset) data set. This data set will also be used in Chapter 5 later. `emnist.nyb` will help you download and set the data up.
Since the data set is large, a contained version is provided in the `./data` directory.
First step will be to unzip these files. Please store the output of the unzipping in the same `./Chapter1/data` directory. Please note that if you want to manage large files, you will need to install `git-lfs` package.

## Setting up Python Environment
[Anaconda](https://www.anaconda.com/distribution/#download-section) for Python 3 is used to manage the dependencies for Python packages. Alternatively you can use `pip` with `virtualenv` to manage dependencies as well. Two files have been provided:

* `conda_requirements.txt` : This has the dependencies generated by `conda list` command for this environment. To create a new Conda virtual environment with this configuration, run `conda create -name <your env name> -file conda_requirements.txt` .
* `pip_requirements.txt`: This file is generated as the output of `pip freeze > pip_requirements.txt` command. To install all dependencies using `pip`, please run the following command instead a virtual environment: `pip install -r pip_requirements.txt`

Using a virtual environment is *highly* recommended.
